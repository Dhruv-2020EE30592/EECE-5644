{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "70WEEUja_8Oo",
        "asYCjFIpAATD",
        "Aain2YH_AP-3",
        "lNhWwAl4BC57",
        "DOB3bCMTCKjX",
        "Eh7_2T5ADkQd",
        "HPvUU7XLDlwV",
        "YjHPoZmVDoS-",
        "GQ4SoIvQ_Dfj",
        "TB23w1u4VILf",
        "mO5p6NHGVLwb",
        "9QjUP3ss-3ce"
      ],
      "mount_file_id": "1VZRpgB4kL1XrAvJ-mBYHPJ4KfeW4m_ZX",
      "authorship_tag": "ABX9TyOydt81BiUJxEBdgyPkwKmm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruv-2020EE30592/EECE-5644/blob/main/Assignment-1/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl_tV0dlTtkz"
      },
      "outputs": [],
      "source": [
        "# Headers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.stats\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_curve, auc\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "70WEEUja_8Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "asYCjFIpAATD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating samples\n",
        "\n",
        "P_L0 = 0.35\n",
        "P_L1 = 0.65\n",
        "\n",
        "mu_0 = [-1, -1, -1, -1]\n",
        "sigma_0 = [[2, -0.5, 0.3, 0], [-0.5, 1, -0.5, 0], [0.3, -0.5, 1, 0], [0, 0, 0, 2]]\n",
        "mu_1 = [1, 1, 1, 1]\n",
        "sigma_1 = [[1, 0.3, -0.2, 0], [0.3, 2, 0.3, 0], [-0.2, 0.3, 1, 0], [0, 0, 0, 3]]\n",
        "\n",
        "N = 10000\n",
        "\n",
        "samples = np.zeros((N, 4))\n",
        "L_samples = np.random.choice([0, 1], size=N, p=[P_L0, P_L1])\n",
        "for i in range(N):\n",
        "  if L_samples[i] == 0:\n",
        "    samples[i] = np.random.multivariate_normal(mu_0, sigma_0)\n",
        "  if L_samples[i] == 1:\n",
        "    samples[i] = np.random.multivariate_normal(mu_1, sigma_1)"
      ],
      "metadata": {
        "id": "aSHBXsqt__Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert samples to a DataFrame for easier plotting with seaborn\n",
        "\n",
        "df = pd.DataFrame(samples, columns=['Dim1', 'Dim2', 'Dim3', 'Dim4'])\n",
        "df['L'] = L_samples\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "iGW3CTy6AG2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting probability density functions for different dimensions\n",
        "\n",
        "for i, dim in enumerate(['Dim1', 'Dim2', 'Dim3', 'Dim4']):\n",
        "    plt.subplot(2, 2, i + 1)  # Create a 2x2 grid of subplots\n",
        "    sns.kdeplot(data=df, x=dim, hue='L', palette={0: 'blue', 1: 'red'}, fill=True)\n",
        "    plt.title(f'Distribution of {dim}')\n",
        "    plt.xlabel(dim)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DPQnOQfyALup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "Aain2YH_AP-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification function\n",
        "\n",
        "def likelihood_ratio_test(x, m0, m1, C0, C1, gamma):\n",
        "  p_x_given_L0 = scipy.stats.multivariate_normal.pdf(x, mean=m0, cov=C0)\n",
        "  p_x_given_L1 = scipy.stats.multivariate_normal.pdf(x, mean=m1, cov=C1)\n",
        "  L_ratio = p_x_given_L1/p_x_given_L0\n",
        "  return L_ratio > gamma"
      ],
      "metadata": {
        "id": "HIVsfhVnAd1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part A: ERM Classification using correct data distribution\n",
        "# Calculating the TPR(True Positive Rate) and FPR(False Positive Rate)\n",
        "\n",
        "gamma_values = np.logspace(-10, 10, num=1000)\n",
        "ERM_mu_0 = [-1, -1, -1, -1]\n",
        "ERM_sigma_0 = [[2, -0.5, 0.3, 0], [-0.5, 1, -0.5, 0], [0.3, -0.5, 1, 0], [0, 0, 0, 2]]\n",
        "ERM_mu_1 = [1, 1, 1, 1]\n",
        "ERM_sigma_1 = [[1, 0.3, -0.2, 0], [0.3, 2, 0.3, 0], [-0.2, 0.3, 1, 0], [0, 0, 0, 3]]\n",
        "\n",
        "TPR = []\n",
        "FPR = []\n",
        "\n",
        "for gamma in gamma_values:\n",
        "  D = likelihood_ratio_test(samples, ERM_mu_0, ERM_mu_1, ERM_sigma_0, ERM_sigma_1, gamma)\n",
        "  TP = np.sum((D == True) & (L_samples == 1))\n",
        "  FN = np.sum((D == False) & (L_samples == 1))\n",
        "  FP = np.sum((D == True) & (L_samples == 0))\n",
        "  TN = np.sum((D == False) & (L_samples == 0))\n",
        "\n",
        "  TPR.append(TP/(TP+FN))\n",
        "  FPR.append(FP/(FP+TN))"
      ],
      "metadata": {
        "id": "LAjM04MdAXY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part B: ERM Classification using incorrect data distribution\n",
        "# Calculating the TPR(True Positive Rate) and FPR(False Positive Rate)\n",
        "\n",
        "gamma_values = np.logspace(-10, 10, num=1000)\n",
        "ERM_mu_0 = [-1, -1, -1, -1]\n",
        "ERM_sigma_0 = [[2, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]]\n",
        "ERM_mu_1 = [1, 1, 1, 1]\n",
        "ERM_sigma_1 = [[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 1, 0], [0, 0, 0, 3]]\n",
        "\n",
        "TPR = []\n",
        "FPR = []\n",
        "\n",
        "for gamma in gamma_values:\n",
        "  D = likelihood_ratio_test(samples, ERM_mu_0, ERM_mu_1, ERM_sigma_0, ERM_sigma_1, gamma)\n",
        "  TP = np.sum((D == True) & (L_samples == 1))\n",
        "  FN = np.sum((D == False) & (L_samples == 1))\n",
        "  FP = np.sum((D == True) & (L_samples == 0))\n",
        "  TN = np.sum((D == False) & (L_samples == 0))\n",
        "\n",
        "  TPR.append(TP/(TP+FN))\n",
        "  FPR.append(FP/(FP+TN))"
      ],
      "metadata": {
        "id": "Qu1odjtfBZ56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part C: ERM Classification using Fisher LDA\n",
        "# Calculating the TPR(True Positive Rate) and FPR(False Positive Rate)\n",
        "\n",
        "samples_L0 = samples[L_samples == 0]\n",
        "samples_L1 = samples[L_samples == 1]\n",
        "\n",
        "# rowvar specifies that columns are features and rows are data points\n",
        "# in SW we multiply by (samples_L0.shape[0] - 1) to reverse normalize\n",
        "# in SB we reshape to convert into column and row vectors\n",
        "LDA_overall_mean = np.mean(samples, axis=0)\n",
        "LDA_mu_0 = np.mean(samples_L0, axis=0)\n",
        "LDA_mu_1 = np.mean(samples_L1, axis=0)\n",
        "LDA_sigma_0 = np.cov(samples_L0, rowvar=False)\n",
        "LDA_sigma_1 = np.cov(samples_L1, rowvar=False)\n",
        "# SW = LDA_sigma_0*(samples_L0.shape[0]-1)+LDA_sigma_1*(samples_L1.shape[0]-1)\n",
        "SW = LDA_sigma_0+LDA_sigma_1\n",
        "# SB = (LDA_mu_0-LDA_overall_mean).reshape(-1, 1)@(LDA_mu_0-LDA_overall_mean).reshape(1, -1)*samples_L0.shape[0] + (LDA_mu_1-LDA_overall_mean).reshape(-1, 1)@(LDA_mu_1-LDA_overall_mean).reshape(1, -1)*samples_L1.shape[0]\n",
        "SB = (LDA_mu_0-LDA_overall_mean).reshape(-1, 1)@(LDA_mu_0-LDA_overall_mean).reshape(1, -1) + (LDA_mu_1-LDA_overall_mean).reshape(-1, 1)@(LDA_mu_1-LDA_overall_mean).reshape(1, -1)\n",
        "\n",
        "# Generalized eigendecomposition\n",
        "eigenvalues, eigenvectors = np.linalg.eig(np.linalg.inv(SW)@SB)\n",
        "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "LDA_w = eigenvectors[:, sorted_indices[0]]\n",
        "\n",
        "# Projecting samples onto largest eigenvector\n",
        "projected_samples = samples @ LDA_w\n",
        "thresholds = np.linspace(np.min(projected_samples), np.max(projected_samples), 1000)\n",
        "TPR = []\n",
        "FPR = []\n",
        "for t in thresholds:\n",
        "  predictions = (projected_samples > t)\n",
        "  TP = np.sum((predictions == True) & (L_samples == 1))\n",
        "  FN = np.sum((predictions == False) & (L_samples == 1))\n",
        "  FP = np.sum((predictions == True) & (L_samples == 0))\n",
        "  TN = np.sum((predictions == False) & (L_samples == 0))\n",
        "\n",
        "  TPR.append(TP/(TP+FN))\n",
        "  FPR.append(FP/(FP+TN))"
      ],
      "metadata": {
        "id": "W-3EPBCSByxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Visualization"
      ],
      "metadata": {
        "id": "lNhWwAl4BC57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Empirical and Theoretical Optimal Threshold\n",
        "\n",
        "fpr = np.array(FPR)\n",
        "tpr = np.array(TPR)\n",
        "\n",
        "P_error = fpr*P_L0 + (1-tpr)*P_L1\n",
        "min_error_index = np.argmin(P_error)\n",
        "print(f'Empirical optimal threshold: {gamma_values[min_error_index]}')\n",
        "print(f'Minimum probability of error: {P_error[min_error_index]}')\n",
        "print(f'Assuming the cost of errors is the same')\n",
        "print(f'Theoretical optimal threshold: {P_L0/P_L1}')"
      ],
      "metadata": {
        "id": "KXb70n9aBFzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting ROC and computing AUROC\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(FPR, TPR, label=\"ROC Curve\")\n",
        "plt.scatter(fpr[min_error_index], tpr[min_error_index], color='red', label='Min P(error) threshold', marker = 'o', s=100)\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"ROC Curve for Classifier\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f'Area under ROC: {auc(FPR, TPR)}')"
      ],
      "metadata": {
        "id": "nmbkzdZqBGR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "DOB3bCMTCKjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "Eh7_2T5ADkQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating samples\n",
        "\n",
        "P_L1 = 0.30\n",
        "P_L2 = 0.30\n",
        "P_L3 = 0.40\n",
        "\n",
        "mu_1 = [0, 0, 0]\n",
        "sigma_1 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "mu_2 = [2, 0, 0]\n",
        "sigma_2 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "mu_3 = [0, 2, 0]\n",
        "sigma_3 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "mu_4 = [0, 2, 2]\n",
        "sigma_4 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "\n",
        "N = 10000\n",
        "\n",
        "samples = np.zeros((N, 3))\n",
        "L_samples = np.random.choice([1, 2, 3], size=N, p=[P_L1, P_L2, P_L3])\n",
        "for i in range(N):\n",
        "  if L_samples[i] == 1:\n",
        "    samples[i] = np.random.multivariate_normal(mu_1, sigma_1)\n",
        "  if L_samples[i] == 2:\n",
        "    samples[i] = np.random.multivariate_normal(mu_2, sigma_2)\n",
        "  if L_samples[i] == 3:\n",
        "    a = np.random.choice([0, 1], p=[0.5, 0.5])\n",
        "    if a == 0:\n",
        "      samples[i] = np.random.multivariate_normal(mu_3, sigma_3)\n",
        "    else:\n",
        "      samples[i] = np.random.multivariate_normal(mu_4, sigma_4)"
      ],
      "metadata": {
        "id": "e2rAdxWwDsgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize samples\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(samples[L_samples == 1][:, 0], samples[L_samples == 1][:, 1], samples[L_samples == 1][:, 2], color='r', label='Class 1', alpha=0.5)\n",
        "ax.scatter(samples[L_samples == 2][:, 0], samples[L_samples == 2][:, 1], samples[L_samples == 2][:, 2], color='g', label='Class 2', alpha=0.5)\n",
        "ax.scatter(samples[L_samples == 3][:, 0], samples[L_samples == 3][:, 1], samples[L_samples == 3][:, 2], color='b', label='Class 3', alpha=0.5)\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('X3')\n",
        "ax.legend()\n",
        "plt.title('Samples from Mixture of 4 Gaussians')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J74qxWnDDwP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part A: MPE Classifier"
      ],
      "metadata": {
        "id": "HPvUU7XLDlwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification based on max posterior probability\n",
        "\n",
        "def MPE_classifier(x):\n",
        "  post_L1 = P_L1 * scipy.stats.multivariate_normal.pdf(x, mean=mu_1, cov=sigma_1)\n",
        "  post_L2 = P_L2 * scipy.stats.multivariate_normal.pdf(x, mean=mu_2, cov=sigma_2)\n",
        "  post_L3 = P_L3 * (0.5*scipy.stats.multivariate_normal.pdf(x, mean=mu_3, cov=sigma_3) + 0.5*scipy.stats.multivariate_normal.pdf(x, mean=mu_1, cov=sigma_1))\n",
        "  return np.argmax(np.stack([post_L1, post_L2, post_L3], axis=1), axis=1)+1\n",
        "\n",
        "D_samples = np.array([MPE_classifier(samples)])"
      ],
      "metadata": {
        "id": "ZJLamnnJNI2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix = np.zeros((3, 3))\n",
        "correct_assignments = 0\n",
        "total_samples = 0\n",
        "for i in range(1, 4):\n",
        "  for j in range(1, 4):\n",
        "    confusion_matrix[i-1, j-1] = np.sum((L_samples == i) & (D_samples == j)) / np.sum(L_samples == i)\n",
        "    if i == j:\n",
        "      correct_assignments += np.sum((L_samples == i) & (D_samples == j))\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='.2f', xticklabels=[f'D={i}' for i in range(1, 4)], yticklabels=[f'L={i}' for i in range(1, 4)])\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "print(f'Accuracy: {correct_assignments/10000}')"
      ],
      "metadata": {
        "id": "zryS-gk-NeM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of data\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "markers = {1: 'x', 2: 'o', 3: '^'}\n",
        "for i in range(1, 4):\n",
        "  correct_idx = (L_samples == i) & (L_samples == D_samples.reshape(-1))\n",
        "  incorrect_idx = (L_samples == i) & (L_samples != D_samples.reshape(-1))\n",
        "  ax.scatter(samples[correct_idx, 0], samples[correct_idx, 1], samples[correct_idx, 2], c='green', marker=markers[i], label=f'Class {i} Correct', alpha = 0.3)\n",
        "  ax.scatter(samples[incorrect_idx, 0], samples[incorrect_idx, 1], samples[incorrect_idx, 2], c='red', marker=markers[i], label=f'Class {i} Incorrect', alpha = 0.3)\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('X3')\n",
        "ax.legend()\n",
        "plt.title('Plot with Classification Result')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YdY3eZFINR9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part B: ERM Classification"
      ],
      "metadata": {
        "id": "YjHPoZmVDoS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ERM Classification\n",
        "\n",
        "def ERM_classifier(x, loss_matrix):\n",
        "  post_L1 = scipy.stats.multivariate_normal.pdf(x, mean=mu_1, cov=sigma_1)\n",
        "  post_L2 = scipy.stats.multivariate_normal.pdf(x, mean=mu_2, cov=sigma_2)\n",
        "  post_L3 = (0.5*scipy.stats.multivariate_normal.pdf(x, mean=mu_3, cov=sigma_3) + 0.5*scipy.stats.multivariate_normal.pdf(x, mean=mu_1, cov=sigma_1))\n",
        "  risks = np.zeros((samples.shape[0], 3))\n",
        "  for i in range(3):\n",
        "    risks[:, i] = np.dot(np.stack([post_L1, post_L2, post_L3], axis=1), loss_matrix[i, :])\n",
        "  D_samples = np.argmin(risks, axis=1)+1\n",
        "  return D_samples\n",
        "\n",
        "Lambda_1 = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
        "Lambda_10 = np.array([[0, 10, 10], [1, 0, 10], [1, 1, 0]])\n",
        "Lambda_100 = np.array([[0, 100, 100], [1, 0, 100], [1, 1, 0]])\n",
        "D_samples_1 = ERM_classifier(samples, Lambda_1)\n",
        "D_samples_10 = ERM_classifier(samples, Lambda_10)\n",
        "D_samples_100 = ERM_classifier(samples, Lambda_100)"
      ],
      "metadata": {
        "id": "jaJovrdhNv1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected Risk\n",
        "\n",
        "confusion_matrix_1 = np.zeros((3, 3))\n",
        "confusion_matrix_10 = np.zeros((3, 3))\n",
        "confusion_matrix_100 = np.zeros((3, 3))\n",
        "correct_assignments_1 = 0\n",
        "correct_assignments_10 = 0\n",
        "correct_assignments_100 = 0\n",
        "\n",
        "for i in range(1, 4):\n",
        "  for j in range(1, 4):\n",
        "    confusion_matrix_1[i-1, j-1] = np.sum((L_samples == i) & (D_samples_1 == j)) / np.sum(L_samples == i)\n",
        "    confusion_matrix_10[i-1, j-1] = np.sum((L_samples == i) & (D_samples_10 == j)) / np.sum(L_samples == i)\n",
        "    confusion_matrix_100[i-1, j-1] = np.sum((L_samples == i) & (D_samples_100 == j)) / np.sum(L_samples == i)\n",
        "    if i == j:\n",
        "      correct_assignments_1 += np.sum((L_samples == i) & (D_samples_1 == j))\n",
        "      correct_assignments_10 += np.sum((L_samples == i) & (D_samples_10 == j))\n",
        "      correct_assignments_100 += np.sum((L_samples == i) & (D_samples_100 == j))\n",
        "\n",
        "print(f'Expected Risk with Lambda_1: {np.sum(confusion_matrix_1*Lambda_1)}')\n",
        "print(f'Expected Risk with Lambda_10: {np.sum(confusion_matrix_10*Lambda_10)}')\n",
        "print(f'Expected Risk with Lambda_100: {np.sum(confusion_matrix_100*Lambda_100)}')"
      ],
      "metadata": {
        "id": "ky-1GYbdN2zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_1, annot=True, cmap='Blues', fmt='.2f', xticklabels=[f'D={i}' for i in range(1, 4)], yticklabels=[f'L={i}' for i in range(1, 4)])\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "print(f'Accuracy: {correct_assignments_1/10000}')"
      ],
      "metadata": {
        "id": "U_AsWgGc2oKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_10, annot=True, cmap='Blues', fmt='.2f', xticklabels=[f'D={i}' for i in range(1, 4)], yticklabels=[f'L={i}' for i in range(1, 4)])\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "print(f'Accuracy: {correct_assignments_10/10000}')"
      ],
      "metadata": {
        "id": "pNgHCi2n1rDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_100, annot=True, cmap='Blues', fmt='.2f', xticklabels=[f'D={i}' for i in range(1, 4)], yticklabels=[f'L={i}' for i in range(1, 4)])\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "print(f'Accuracy: {correct_assignments_100/10000}')"
      ],
      "metadata": {
        "id": "xjE6N9D32HEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "GQ4SoIvQ_Dfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "TB23w1u4VILf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "IPer3qAWU5oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data 1\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "wine_quality = fetch_ucirepo(id=186)\n",
        "X = wine_quality.data.features\n",
        "y = wine_quality.data.targets\n",
        "\n",
        "wine_quality.data.original.head()"
      ],
      "metadata": {
        "id": "7f1BqDtvUKRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data 2\n",
        "# Not considering subjects as either features or labels\n",
        "\n",
        "file_path = '/content/drive/MyDrive/EECE 5644/Assignment-1/UCI HAR Dataset'\n",
        "\n",
        "features = pd.read_csv(os.path.join(file_path, 'features.txt'), sep='\\s+', header=None)\n",
        "activity_labels = pd.read_csv(os.path.join(file_path, 'activity_labels.txt'), sep='\\s+', header=None)\n",
        "\n",
        "train_data = pd.read_csv(os.path.join(file_path, 'train/X_train.txt'), sep='\\s+', header=None)\n",
        "train_labels = pd.read_csv(os.path.join(file_path, 'train/y_train.txt'), sep='\\s+', header=None)\n",
        "# train_subjects = pd.read_csv(os.path.join(file_path, 'train/subject_train.txt'), sep='\\s+', header=None)\n",
        "\n",
        "test_data = pd.read_csv(os.path.join(file_path, 'test/X_test.txt'), sep='\\s+', header=None)\n",
        "test_labels = pd.read_csv(os.path.join(file_path, 'test/y_test.txt'), sep='\\s+', header=None)\n",
        "# test_subjects = pd.read_csv(os.path.join(file_path, 'test/subject_test.txt'), sep='\\s+', header=None)"
      ],
      "metadata": {
        "id": "1x33xBttObMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays\n",
        "# Data 1\n",
        "\n",
        "X = X.values\n",
        "y = y.values.reshape(-1)"
      ],
      "metadata": {
        "id": "Uc2vcFK_Uy7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays\n",
        "# Data 2\n",
        "\n",
        "X_train = train_data.values\n",
        "y_train = train_labels.values.reshape(-1)\n",
        "X_test = test_data.values\n",
        "y_test = test_labels.values.reshape(-1)"
      ],
      "metadata": {
        "id": "VQ6g_ARbAkEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "mO5p6NHGVLwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MPE Classifier\n",
        "# For regularization, geometric mean of non-zero eigenvalues gives best result\n",
        "# For non-zero eigenvalues, eigenvalues > 0 gives errors, eigenvalues > 1e-10 does not\n",
        "# c_const = 0.1 gives best F1 score\n",
        "# Vectorized map was used to get back the original classes from idx\n",
        "\n",
        "def MPE_Classifier(X_train, y_train, X_test, y_test, c_const=1e-1, epsilon=1e-10, reg_method='geometric mean'):\n",
        "  classes = np.unique(y_train)\n",
        "  n_samples = X_test.shape[0]\n",
        "  n_features = X_test.shape[1]\n",
        "  n_classes = len(classes)\n",
        "\n",
        "  means = {}\n",
        "  covariances = {}\n",
        "  priors = {}\n",
        "  for cls in classes:\n",
        "    X_cls = X_train[y_train == cls]\n",
        "    means[cls] = np.mean(X_cls, axis=0)\n",
        "    cov_matrix = np.cov(X_cls, rowvar=False)\n",
        "    eigenvalues, _ = np.linalg.eigh(cov_matrix)\n",
        "    nonzero_eigenvalues = eigenvalues[eigenvalues > 1e-10]\n",
        "    if reg_method == 'geometric mean':\n",
        "      reg_const = c_const * np.exp(np.mean(np.log(nonzero_eigenvalues)))\n",
        "    elif reg_method == 'arithmetic mean':\n",
        "      reg_const = c_const * np.mean(nonzero_eigenvalues)\n",
        "    else:\n",
        "      reg_const = c_const\n",
        "    covariances[cls] = cov_matrix + reg_const * np.eye(cov_matrix.shape[0])\n",
        "    priors[cls] = X_cls.shape[0]/X_train.shape[0]\n",
        "\n",
        "  discriminants = np.zeros((n_samples, n_classes))\n",
        "  for idx, cls in enumerate(classes):\n",
        "    discriminants[:, idx] = np.log(scipy.stats.multivariate_normal.pdf(X_test, means[cls], covariances[cls])+epsilon)+np.log(priors[cls]+epsilon)\n",
        "  predicted_classes = np.argmax(discriminants, axis=1)\n",
        "\n",
        "  def map_value(x):\n",
        "    for idx, cls in enumerate(classes):\n",
        "      if x == idx:\n",
        "        return cls\n",
        "  vectorized_map = np.vectorize(map_value)\n",
        "  predicted_classes = vectorized_map(predicted_classes)\n",
        "\n",
        "  return predicted_classes"
      ],
      "metadata": {
        "id": "PBxjSpLoVGgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "# Data 1\n",
        "# X gives better result than X_scaled\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# y_pred = MPE_Classifier(X_scaled, y)\n",
        "y_pred = MPE_Classifier(X, y, X, y, 1e-2, 1e-10, 'none')"
      ],
      "metadata": {
        "id": "rSwUCDnm79fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "# Data 2\n",
        "# X gives better result than X_scaled\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "# y_pred = MPE_Classifier(X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "y_pred = MPE_Classifier(X_train, y_train, X_test, y_test, 1e-1, 1e-10, 'arithmetic mean')\n",
        "X = X_test\n",
        "y = y_test"
      ],
      "metadata": {
        "id": "4vJtLMLmAf_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Visualization"
      ],
      "metadata": {
        "id": "9QjUP3ss-3ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "classes = np.unique(y)\n",
        "sns.heatmap(confusion_matrix(y, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ol4DplylmCV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 Score and Error Probability Estimate\n",
        "\n",
        "print(f\"F1 score (Weighted): {f1_score(y, y_pred, average='weighted')}\")\n",
        "print(f\"Error Probability Estimate: {1 - accuracy_score(y, y_pred)}\")"
      ],
      "metadata": {
        "id": "RLAIO6HduCui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing principal components for data\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "# X_pca = pca.fit_transform(X_scaled)\n",
        "X_pca = pca.fit_transform(X)\n",
        "print(\"Amount of variance associated with each component:\", pca.explained_variance_ratio_)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, edgecolor='k', cmap='viridis')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA Result')\n",
        "plt.colorbar(label='Class Label')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dxjKWbSm4Gp5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}